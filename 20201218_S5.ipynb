{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f953615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Read the dataset\n",
    "def read_dataset(file_path, percentage):\n",
    "    dataset = pd.read_csv(file_path)\n",
    "\n",
    "    # Calculate the number of records to use based on the percentage provided by the user\n",
    "    total_records = len(dataset)\n",
    "    records_to_use = int((percentage / 100) * total_records)\n",
    "\n",
    "    # Extract the specified percentage of records from the dataset\n",
    "    dataset = dataset.head(records_to_use)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Step 2: Split dataset into training and testing sets\n",
    "def split_dataset(dataset, test_size):\n",
    "    train_data = dataset.sample(frac=1-test_size, random_state=42)\n",
    "    test_data = dataset.drop(train_data.index)\n",
    "    return train_data, test_data\n",
    "\n",
    "# Step 3: Preprocess the data\n",
    "def preprocess_data(training_data, testing_data):\n",
    "    # Separate features and labels\n",
    "    X_train = training_data.drop(columns=['diabetes']).values\n",
    "    y_train = training_data['diabetes'].astype(int).values\n",
    "    X_test = testing_data.drop(columns=['diabetes']).values\n",
    "    y_test = testing_data['diabetes'].astype(int).values\n",
    "\n",
    "    # Encode categorical variables\n",
    "    X_train, X_test = encode_categorical_variables(X_train, X_test)\n",
    "\n",
    "    # Handle missing values\n",
    "    X_train, X_test = handle_missing_values(X_train, X_test)\n",
    "\n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Encode categorical variables\n",
    "def encode_categorical_variables(X_train, X_test):\n",
    "    gender_encoder = LabelEncoder()\n",
    "    smoking_encoder = LabelEncoder()\n",
    "\n",
    "    # Encode 'gender' column\n",
    "    X_train[:, 0] = gender_encoder.fit_transform(X_train[:, 0])\n",
    "    X_test[:, 0] = gender_encoder.transform(X_test[:, 0])\n",
    "\n",
    "    # Encode 'smoking_history' column\n",
    "    X_train[:, 4] = smoking_encoder.fit_transform(X_train[:, 4])\n",
    "    X_test[:, 4] = smoking_encoder.transform(X_test[:, 4])\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "# Handle missing values\n",
    "def handle_missing_values(X_train, X_test):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_probabilities = {}\n",
    "        self.feature_probabilities = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "\n",
    "        # Calculate class probabilities\n",
    "        for cls in self.classes:\n",
    "            self.class_probabilities[cls] = np.sum(y == cls) / n_samples\n",
    "\n",
    "        # Calculate feature probabilities\n",
    "        for cls in self.classes:\n",
    "            self.feature_probabilities[cls] = {}\n",
    "            for feature_idx in range(n_features):\n",
    "                feature_values = X[y == cls, feature_idx]\n",
    "                self.feature_probabilities[cls][feature_idx] = {\n",
    "                    'mean': np.mean(feature_values),\n",
    "                    'std': np.std(feature_values)\n",
    "                }\n",
    "\n",
    "    def _calculate_probability(self, x, mean, std):\n",
    "        exponent = np.exp(-((x - mean) ** 2) / (2 * (std ** 2)))\n",
    "        return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
    "\n",
    "    def _calculate_class_probability(self, x, cls):\n",
    "        class_probability = self.class_probabilities[cls]\n",
    "        for feature_idx, value in enumerate(x):\n",
    "            mean = self.feature_probabilities[cls][feature_idx]['mean']\n",
    "            std = self.feature_probabilities[cls][feature_idx]['std']\n",
    "            class_probability *= self._calculate_probability(value, mean, std)\n",
    "        return class_probability\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            class_probabilities = {\n",
    "                cls: self._calculate_class_probability(x, cls)\n",
    "                for cls in self.classes\n",
    "            }\n",
    "            predicted_class = max(class_probabilities, key=class_probabilities.get)\n",
    "            predictions.append(predicted_class)\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        \n",
    "        entropy = -np.sum(probabilities * np.log2(probabilities + 1e-9))  # Adding a small value to avoid log(0)\n",
    "        return entropy\n",
    "\n",
    "    def _information_gain(self, X, y, feature_idx, threshold):\n",
    "        left_mask = X[:, feature_idx] <= threshold\n",
    "        right_mask = ~left_mask\n",
    "        n_total = len(y)\n",
    "        n_left, n_right = np.sum(left_mask), np.sum(right_mask)\n",
    "        if n_left == 0 or n_right == 0:\n",
    "            return 0\n",
    "        entropy_parent = self._entropy(y)\n",
    "        entropy_left = self._entropy(y[left_mask])\n",
    "        entropy_right = self._entropy(y[right_mask])\n",
    "        information_gain = entropy_parent - (n_left / n_total) * entropy_left - (n_right / n_total) * entropy_right\n",
    "        return information_gain\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_information_gain = -1\n",
    "        best_feature_idx = None\n",
    "        best_threshold = None\n",
    "        n_samples, n_features = X.shape\n",
    "        for feature_idx in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                information_gain = self._information_gain(X, y, feature_idx, threshold)\n",
    "                if information_gain > best_information_gain:\n",
    "                    best_information_gain = information_gain\n",
    "                    best_feature_idx = feature_idx\n",
    "                    best_threshold = threshold\n",
    "        return best_feature_idx, best_threshold\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "        if len(unique_classes) == 1 or n_samples < 2 or depth == self.max_depth:\n",
    "            return (None, None, None, None, unique_classes[0])  # Return the class label of the majority class\n",
    "        best_feature_idx, best_threshold = self._find_best_split(X, y)\n",
    "        if best_feature_idx is None:\n",
    "            return (None, None, None, None, unique_classes[0])  # Return the class label of the majority class\n",
    "        left_mask = X[:, best_feature_idx] <= best_threshold\n",
    "        right_mask = ~left_mask\n",
    "        left_subtree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        return (best_feature_idx, best_threshold, left_subtree, right_subtree, None)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def _predict_instance(self, x, tree):\n",
    "        if isinstance(tree, int):\n",
    "            return tree\n",
    "        feature_idx, threshold, left_subtree, right_subtree, class_label = tree\n",
    "        if class_label is not None:\n",
    "            return class_label\n",
    "        if x[feature_idx] <= threshold:\n",
    "            return self._predict_instance(x, left_subtree)\n",
    "        else:\n",
    "            return self._predict_instance(x, right_subtree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_instance(x, self.tree) for x in X])\n",
    "\n",
    "# Main function to orchestrate the process\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Diabetes Classifier\")\n",
    "    root.geometry(\"400x400\")\n",
    "\n",
    "    # Function to handle file browse button click\n",
    "    def browse_file():\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "        file_path_var.set(file_path)\n",
    "\n",
    "    # File path entry\n",
    "    file_path_var = tk.StringVar()\n",
    "    file_path_label = tk.Label(root, text=\"File Path:\")\n",
    "    file_path_label.pack()\n",
    "    file_path_entry = tk.Entry(root, textvariable=file_path_var)\n",
    "    file_path_entry.pack()\n",
    "\n",
    "    # Browse file button\n",
    "    browse_button = tk.Button(root, text=\"Browse\", command=browse_file)\n",
    "    browse_button.pack()\n",
    "\n",
    "    # Percentage entry\n",
    "    percentage_var = tk.DoubleVar()\n",
    "    percentage_label = tk.Label(root, text=\"Percentage to Use:\")\n",
    "    percentage_label.pack()\n",
    "    percentage_entry = tk.Entry(root, textvariable=percentage_var)\n",
    "    percentage_entry.pack()\n",
    "\n",
    "    # Output text area\n",
    "    output_text = tk.Text(root, height=10, width=50)\n",
    "    output_text.pack()\n",
    "\n",
    "    # Run button\n",
    "    run_button = tk.Button(root, text=\"Run Classifier\", command=lambda: run_classifier(file_path_var.get(), percentage_var.get(), output_text))\n",
    "    run_button.pack()\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "def run_classifier(file_path, percentage, output_text):\n",
    "    try:\n",
    "        percentage = float(percentage)\n",
    "        dataset= read_dataset(file_path, percentage)\n",
    "\n",
    "        # User inputs\n",
    "        test_size = 0.25  # Percentage of data to use for testing\n",
    "\n",
    "        # Step 2: Divide the dataset into training and testing sets\n",
    "        training_data, testing_data = split_dataset(dataset, test_size)\n",
    "\n",
    "        # Step 3: Preprocess the data\n",
    "        X_train, X_test, y_train, y_test = preprocess_data(training_data, testing_data)\n",
    "\n",
    "        # Print the shapes of the resulting datasets\n",
    "        output_text.insert(tk.END, f\"Training set size: {len(X_train)}, {len(y_train)}\\n\")\n",
    "        output_text.insert(tk.END, f\"Testing set size: {len(X_test)}, {len(y_test)}\\n\")\n",
    "\n",
    "        # Step 4: Train and evaluate classifiers\n",
    "        bayesian_classifier = NaiveBayesClassifier()\n",
    "        bayesian_classifier.fit(X_train, y_train)\n",
    "        bayesian_predictions = bayesian_classifier.predict(X_test)\n",
    "        bayesian_accuracy = accuracy_score(y_test, bayesian_predictions)\n",
    "        output_text.insert(tk.END, f\"Accuracy of Bayesian classifier: {bayesian_accuracy}\\n\")\n",
    "\n",
    "        decision_tree_classifier = DecisionTreeClassifier(max_depth=5)  # Example depth, you can adjust it\n",
    "        decision_tree_classifier.fit(X_train, y_train)\n",
    "        decision_tree_predictions = decision_tree_classifier.predict(X_test)\n",
    "        decision_tree_accuracy = accuracy_score(y_test, decision_tree_predictions)\n",
    "        output_text.insert(tk.END, f\"Accuracy of Decision Tree classifier: {decision_tree_accuracy}\\n\")\n",
    "\n",
    "        # Output each row in test along with its actual and predicted labels\n",
    "        output_text.insert(tk.END, \"\\nTest Data Predictions:\\n\")\n",
    "        for i, (idx, row) in enumerate(testing_data.iterrows()):\n",
    "            output_text.insert(tk.END, f\"Test Row {i+1}\\n\")\n",
    "            output_text.insert(tk.END, f\"Actual Label: {row['diabetes']}\\n\")\n",
    "#             output_text.insert(tk.END, \"Test Data (Before Preprocessing):\\n\")\n",
    "            \n",
    "#             # Extract the ID value\n",
    "#             id_value = row['id']  # Assuming 'id' is the name of the ID column\n",
    "#             output_text.insert(tk.END, f\"ID: {id_value}\\n\")\n",
    "            \n",
    "            output_text.insert(tk.END, f\"Predicted Label (Bayesian): {bayesian_predictions[i]}\\n\")\n",
    "            output_text.insert(tk.END, f\"Predicted Label (Decision Tree): {decision_tree_predictions[i]}\\n\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a8c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ac46a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
